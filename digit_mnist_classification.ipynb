{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asafbigel/digit_classification/blob/main/digit_mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp7BrfqHRNqN"
      },
      "source": [
        "# Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set iterations number"
      ],
      "metadata": {
        "id": "e8YauW_huH-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt9ltaz8RktT"
      },
      "outputs": [],
      "source": [
        "NUM_OF_ITERATION_PLA = 1000\n",
        "NUM_OF_ITERATION_SOFTMAX = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvZs61ICS6QN"
      },
      "source": [
        "Import librarys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcHmmbJ-JC6e"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNA8fr62JGZU"
      },
      "source": [
        "Fetch MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf1wLGfgS6QP"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "# Access features (pixel values) and labels\n",
        "X, y = mnist['data'], mnist['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE3gXjJNR4Zr"
      },
      "source": [
        "Fix X values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZA31fktR-EE"
      },
      "outputs": [],
      "source": [
        "X = X/255\n",
        "\n",
        "# add a column of ones to the features for the bias term\n",
        "X = np.c_[np.ones(X.shape[0]), X]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4N22qkBjz7I"
      },
      "source": [
        "Convert y to array integer (one-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzuy53AujQPq"
      },
      "outputs": [],
      "source": [
        "y = y.astype(int)\n",
        "temp = np.full((len(y), 10), 0)\n",
        "for i in range(len(y)):\n",
        "  temp[i, y[i]] = 1\n",
        "y = temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83fklxRgS6QQ"
      },
      "source": [
        "Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK3de230S6QQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=(1/7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirw7_N5S6QQ"
      },
      "source": [
        "# **Perceptron Learning Algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAbn7sWSS6QQ"
      },
      "source": [
        "Define the misclassified recognize function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNRLE5v0S6QQ"
      },
      "outputs": [],
      "source": [
        "def evaluate(w, X, y):\n",
        "    predictions = np.sign(X @ w)\n",
        "    misclassified = X[predictions != y]\n",
        "    misclassified_labels = y[predictions != y]\n",
        "    return misclassified, misclassified_labels\n",
        "\n",
        "def percetron_train(w0, X, y, j):\n",
        "    num_of_errors = len(y)\n",
        "    pass_rate = 0\n",
        "    pbar = tqdm(range(NUM_OF_ITERATION_PLA), desc='Num of iterations', leave=False)\n",
        "    for i in pbar:\n",
        "        misclassifieds, misclassifieds_labels = evaluate(w0, X, y)\n",
        "        if len(misclassifieds) <= num_of_errors:\n",
        "            num_of_errors = len(misclassifieds)\n",
        "            best_w = w0\n",
        "            pass_rate = ((len(y) - num_of_errors) /  len(y)) * 100\n",
        "            print (f\"\"\"\\rTrain digit: {j}. Errors: {num_of_errors}, pass rate: {pass_rate:.0f}%. Iteration num: {i}\"\"\", end ='')\n",
        "\n",
        "        if len(misclassifieds) == 0: # or pass_rate >= 97:\n",
        "          pbar.close()\n",
        "          break\n",
        "\n",
        "        # Update weights\n",
        "        rand = np.random.randint(0, len(misclassifieds))\n",
        "        x0 = misclassifieds[rand]\n",
        "        y0 = misclassifieds_labels[rand]\n",
        "        w0 = w0 + x0 * y0\n",
        "    print(\"\")\n",
        "    return best_w\n",
        "\n",
        "def digit_flow(w, y, i):\n",
        "    w[i] = percetron_train(w[i], X_train, y, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of weights for each digit (0-9).\n",
        "\n",
        "Change from 0/1 lables, to -1/1 labels"
      ],
      "metadata": {
        "id": "fahHgrYGtQ_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVrYEO0JS79q"
      },
      "outputs": [],
      "source": [
        "w = np.zeros((10,785))\n",
        "y_train_0 = y_train.copy()\n",
        "y_test_0 = y_test.copy()\n",
        "y_train_0[y_train_0 == 0] = -1\n",
        "y_test_0[y_test_0 == 0] = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the PLA for each digit"
      ],
      "metadata": {
        "id": "oh0WpOzUtmOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HkWeuzEsS6QQ"
      },
      "outputs": [],
      "source": [
        "# Save timestamp\n",
        "start = time.time()\n",
        "\n",
        "for j in tqdm(range(10), desc=f'Training for all digits'):\n",
        "\n",
        "  digit_flow(w, y_train_0[:,j], j)\n",
        "\n",
        "# Save timestamp\n",
        "end = time.time()\n",
        "PLA_time = end - start\n",
        "print(f\"total time: {PLA_time} for {NUM_OF_ITERATION_PLA} iterations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBPGdZfJ1UnU"
      },
      "source": [
        "predict the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "60oxCai61Zdq"
      },
      "outputs": [],
      "source": [
        "predictions = np.empty((10, len(y_test)))\n",
        "\n",
        "for j in range(10):\n",
        "\n",
        "  predictions[j] = np.sign(X_test @ w[j])\n",
        "\n",
        "  TP = np.sum((predictions[j] == 1) & (y_test_0[:, j] == 1))\n",
        "  TN = np.sum((predictions[j] == -1) & (y_test_0[:, j] == -1))\n",
        "  FP = np.sum((predictions[j] == 1) & (y_test_0[:, j] == -1))\n",
        "  FN = np.sum((predictions[j] == -1) & (y_test_0[:, j] == 1))\n",
        "\n",
        "  Accuracy = (TP+TN)/(TP+TN+FP+FN) * 100\n",
        "  sensitivity = TP/(TP+FN) * 100\n",
        "  specificity = TN/(TN+FP) * 100\n",
        "\n",
        "  print(f'For digit {j}: Accuracy : {Accuracy:.2f}% , sensitivity : {sensitivity:.2f}% , specificity : {specificity:.2f}%')\n",
        "\n",
        "  conf_matrix = confusion_matrix(y_test_0[:, j], predictions[j])\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_matrix)\n",
        "  cm_display.plot()\n",
        "  cm_display.ax_.set_title(f\"Confusion Matrix for digit {j}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the total result for the PLA complet module"
      ],
      "metadata": {
        "id": "bsATfImLt6Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGtnzwEuoWw_"
      },
      "outputs": [],
      "source": [
        "# find the real prediction in regular mode instead of one-hot\n",
        "y_test_indices = np.argmax(y_test_0, axis=1)\n",
        "h_hat_indices = np.argmax(predictions, axis=0)\n",
        "\n",
        "accuracy_PLA = h_hat_indices[h_hat_indices==y_test_indices].shape[0]*100/y_test.shape[0]\n",
        "print(f'Accuracy: {accuracy_PLA:.2f}%')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_indices, h_hat_indices)\n",
        "\n",
        "display_labels = [str(i) for i in range(y_test.shape[1])]\n",
        "\n",
        "cm_display_PLA = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = display_labels)\n",
        "cm_display_PLA.plot()\n",
        "cm_display_PLA.ax_.set_title(f\"Confusion Matrix for PLA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkqqO9bcajW"
      },
      "source": [
        "# Softmax Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set the functions"
      ],
      "metadata": {
        "id": "tqkZ7vUAznA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga9R6RiVccPM"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def yhat(w, X):\n",
        "  return sigmoid(X@w)\n",
        "\n",
        "def J(w,X,y,yh):\n",
        "  \"\"\"\n",
        "  Loss function\n",
        "  cross entropy function\n",
        "  \"\"\"\n",
        "  m = X.shape[0]*10\n",
        "  i = (-y * np.log(yh) - (1-y) * np.log(1-yh))\n",
        "  j = (1/(m)) * np.sum(i)\n",
        "  return j\n",
        "\n",
        "def dw(w,X,y,yh):\n",
        "  m = X.shape[0]*10\n",
        "  dw = (1/m) * X.T@(yh-y)\n",
        "  return dw\n",
        "def db(w, X,y, yh):\n",
        "  m = X.shape[0]*10\n",
        "  return (1/m) * np.sum(yh-y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7AVXKEtT6bA"
      },
      "outputs": [],
      "source": [
        "def softmax(z):\n",
        "  \"Return the softmax output of a vector\"\n",
        "  exp_z = np.exp(z)\n",
        "  sum = exp_z.sum()\n",
        "  softmax_z = np.round(exp_z/sum, 3)\n",
        "  return softmax_z"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set the W, alpha, anf j list"
      ],
      "metadata": {
        "id": "sEdKSda3z47w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz-AUk2vTnh_"
      },
      "outputs": [],
      "source": [
        "w1 = np.zeros((785, 10))\n",
        "# set the bias\n",
        "w1[784,:] = 0.01\n",
        "alpha = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sOO17DDTnh_"
      },
      "outputs": [],
      "source": [
        "# errors count list\n",
        "j_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdMMB6JTnh-"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JnUEcIFXT0E"
      },
      "outputs": [],
      "source": [
        "# Save timestamp\n",
        "start = time.time()\n",
        "\n",
        "for i in tqdm(range(NUM_OF_ITERATION_SOFTMAX)):\n",
        "  yh = yhat(w1,X_train)\n",
        "  dw_ = dw(w1,X_train,y_train,yh)\n",
        "  w1 -= alpha*dw_\n",
        "  j = J(w1, X_train, y_train,yh)\n",
        "  j_list.append(j)\n",
        "  if (i%10 == 0):\n",
        "    print (f\"\"\"\\rj (error rate): {j}\"\"\", end ='')\n",
        "\n",
        "# Save timestamp\n",
        "end = time.time()\n",
        "softmax_time = end- start\n",
        "print()\n",
        "print(f'len j_list (count of iterations): {len(j_list)}')\n",
        "print(f'j = {j}')\n",
        "print(f\"total time: {softmax_time} for {NUM_OF_ITERATION_SOFTMAX} iterations\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(j_list)"
      ],
      "metadata": {
        "id": "7Sad9WlBfZ3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF8dhNcEaPPr"
      },
      "outputs": [],
      "source": [
        "plt.plot(j_list[-50:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ezzZTFerRZt"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlr0k_1E6YcI"
      },
      "outputs": [],
      "source": [
        "predicts = (X_test@w1)\n",
        "predicted_classes = np.argmax(predicts, axis=1)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# find the real prediction in regular mode instead of one-hot\n",
        "y_test_indices = np.argmax(y_test, axis=1)\n",
        "h_hat_indices = np.argmax(predicts, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_indices, h_hat_indices)\n",
        "\n",
        "display_labels = [str(i) for i in range(y_test.shape[1])]\n",
        "\n",
        "cm_display_softmax = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = display_labels)\n",
        "cm_display_softmax.plot()\n",
        "cm_display_softmax.ax_.set_title(f\"Confusion Matrix for Softmax Regression\")\n",
        "\n",
        "Accuracy_softmax = h_hat_indices[h_hat_indices==y_test_indices].shape[0]*100/y_test.shape[0]\n",
        "print(f'Accuracy: {Accuracy_softmax:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the table of confusion for each digit and compute sensitivity (TPR) for each class\n"
      ],
      "metadata": {
        "id": "uAIidocevnWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzwhyHYeqrGf"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  TP = np.sum((h_hat_indices == i) & (y_test_indices == i))\n",
        "  accuracy = TP / np.sum(y_test_indices == i)\n",
        "  print(f'For digit {i}, accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "866rYc-XImSB"
      },
      "source": [
        "# Linear regration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDnRgz5YTnh_"
      },
      "outputs": [],
      "source": [
        "X2 = X_train\n",
        "y2 = y_train\n",
        "\n",
        "# Save timestamp\n",
        "start = time.time()\n",
        "\n",
        "w2 = (np.linalg.pinv(X2.T @ X2))@(X2.T @ y2)\n",
        "\n",
        "# Save timestamp\n",
        "end = time.time()\n",
        "linear_time = end- start\n",
        "\n",
        "print(f\"total time: {linear_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3B9BLujOTeT"
      },
      "source": [
        "**Predict y_train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g80A67uCOTAC"
      },
      "outputs": [],
      "source": [
        "predicts = X_test@w2\n",
        "yh = np.zeros_like(y_test, dtype=int)\n",
        "yh[np.arange(predicts.shape[0]), predicts.argmax(axis=1)] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00_Ut2OqeSFB"
      },
      "outputs": [],
      "source": [
        "# find the real prediction in regular mode instead of one-hot\n",
        "y_test_indices = np.argmax(y_test, axis=1)\n",
        "h_hat_indices = np.argmax(yh, axis=1)\n",
        "\n",
        "incorect_count = y_test_indices[y_test_indices!=h_hat_indices].shape[0]\n",
        "print(f'incorrect count: {incorect_count}')\n",
        "accuurancy_linear = (predicts.shape[0]-incorect_count)*100/predicts.shape[0]\n",
        "print(f'Accuracy: {accuurancy_linear} %')\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_indices, h_hat_indices)\n",
        "\n",
        "display_labels = [str(i) for i in range(y_test.shape[1])]\n",
        "\n",
        "cm_display_linear = metrics.ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = display_labels)\n",
        "cm_display_linear.plot()\n",
        "cm_display_linear.ax_.set_title(f\"Confusion Matrix for Linear Regression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summery"
      ],
      "metadata": {
        "id": "7mqYrsZf5Epm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m' + 'Summary:' + '\\033[0m')\n",
        "print(\"-\" * 50) # Print a separator line\n",
        "print(f\"{'Model':<20}{'Accuracy (%)':<15}{'Training Time (s)':<20}\")\n",
        "print(\"-\" * 50) # Print a separator line\n",
        "print(f\"{'PLA':<20}{accuracy_PLA:<15.2f}{PLA_time:<20.2f} for {NUM_OF_ITERATION_PLA} iterations\")\n",
        "print(f\"{'Softmax Regression':<20}{Accuracy_softmax:<15.2f}{softmax_time:<20.2f} for {NUM_OF_ITERATION_SOFTMAX} iteration\")\n",
        "print(f\"{'Linear Regression':<20}{accuurancy_linear:<15.2f}{linear_time:<20.2f}\")\n",
        "print(\"-\" * 50) # Print a separator line"
      ],
      "metadata": {
        "id": "i5iCqzao9EOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('\\033[1m' + 'Confusion Matrixs:' + '\\033[0m')\n",
        "cm_display_PLA.plot()\n",
        "cm_display_PLA.ax_.set_title(f\"Confusion Matrix for PLA\")\n",
        "cm_display_softmax.plot()\n",
        "cm_display_softmax.ax_.set_title(f\"Confusion Matrix for Softmax Regression\")\n",
        "cm_display_linear.plot()\n",
        "cm_display_linear.ax_.set_title(f\"Confusion Matrix for Linear Regression\")"
      ],
      "metadata": {
        "id": "BcaXNvCO6rxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**History summery:**\n",
        "\n",
        "--------------------------------------------------\n",
        "| Model               | Accuracy (%) | Training Time (s) | Note               |\n",
        "|---------------------|--------------|-------------------|--------------------|\n",
        "| PLA                 | 47.26        | 52.69             | for 20 iterations  |\n",
        "| Softmax Regression  | 74.18        | 13.59             | for 20 iteration   |\n",
        "| Linear Regression   | 85.14        | 13.33             |                    |\n",
        "|---------------------|--------------|-------------------|--------------------|\n",
        "| PLA                 | 76.20        | 427.89            | for 200 iterations |\n",
        "| Softmax Regression  | 82.18        | 136.80            | for 200 iteration\n",
        "| Linear Regression   | 85.38        | 11.10             |\n",
        "|---------------------|--------------|-------------------|--------------------|\n",
        "| PLA                 | 82.63        | 400.66            | for 1000 iterations\n",
        "| Softmax Regression  | 86.89        | 507.80            | for 1000 iteration\n",
        "| Linear Regression   | 85.55        | 1.90              |  \n",
        "|---------------------|--------------|-------------------|--------------------|\n",
        "| PLA                 | 84.37        | 1729.87           | for 5000 iterations\n",
        "| Softmax Regression  | 89.57        | 2033.50           | for 5000 iteration\n",
        "| Linear Regression   | 85.25        | 1.60                           \n",
        "\n",
        "--------------------------------------------------\n"
      ],
      "metadata": {
        "id": "thWfbRQE_T_v"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "fp7BrfqHRNqN"
      ],
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}